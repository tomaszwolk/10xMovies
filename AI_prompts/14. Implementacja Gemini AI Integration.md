# Implementacja Gemini AI Integration dla Endpointa GET /api/suggestions/

## 🎯 Cel zadania

Zaimplementować rzeczywistą integrację z Google Gemini AI w endpoincie `GET /api/suggestions/`, zastępując obecne mock data prawdziwymi rekomendacjami filmowymi generowanymi przez AI.

## 📋 Kontekst projektu

**Projekt:** MyVOD - aplikacja webowa do zarządzania watchlistą filmów i sprawdzania ich dostępności na platformach VOD.

**Tech Stack:**
- Backend: Django 5.0+ & Django REST Framework
- Database: PostgreSQL 15
- Python: 3.11+
- AI: Google Gemini API

## ✅ Co zostało już zrobione

### 1. Endpoint API (w pełni zaimplementowany)
- ✅ `GET /api/suggestions/` - endpoint do pobierania sugestii AI
- ✅ Pełna obsługa błędów (401, 404, 429, 500)
- ✅ Rate limiting (1 request na dzień)
- ✅ Caching w bazie danych
- ✅ Serializery: `AISuggestionsSerializer`, `SuggestionItemSerializer`, `MovieAvailabilitySerializer`
- ✅ Autentykacja JWT
- ✅ OpenAPI documentation

### 2. Service Layer (`services/ai_suggestions_service.py`)
- ✅ Funkcja `get_or_generate_suggestions(user)` - główna logika biznesowa
- ✅ Funkcja `_generate_new_suggestions(user, expires_at)` - generowanie nowych sugestii
- ✅ **Mock function**: `_generate_mock_suggestions(user, user_movies)` - **TO WYMAGA ZAMIANY NA PRAWDZIWE WYWOŁANIE GEMINI**
- ✅ Funkcja `_get_movie_availability(tconst, platform_ids)` - sprawdzanie dostępności
- ✅ Funkcja `_format_cached_suggestions(user, cached_batch)` - formatowanie cache
- ✅ Funkcja `_log_integration_error(...)` - logowanie błędów do bazy
- ✅ Custom exceptions: `InsufficientDataError`, `RateLimitError`

### 3. Testy (wszystkie przechodzą - 160/160 ✅)
- ✅ Unit testy: `services/tests/test_ai_suggestions_service.py` (15 testów)
- ✅ Integration testy: `myVOD/tests/test_ai_suggestions.py` (12 testów)
- ✅ **Wszystkie testy używają mocków dla wywołania AI** - po implementacji prawdziwego API należy upewnić się, że testy nadal działają

## 📂 Kluczowe pliki projektu

### 1. Główny plik do modyfikacji
```
myVOD/backend/myVOD/services/ai_suggestions_service.py
```
Funkcja do zastąpienia: `_generate_mock_suggestions(user, user_movies)`

### 2. Modele bazy danych
```
myVOD/backend/myVOD/movies/models.py
```
- `Movie` - filmy z IMDB (tconst, primary_title, start_year, avg_rating, genres, etc.)
- `UserMovie` - filmy użytkownika (watchlisted_at, watched_at, added_from_ai_suggestion)
- `AiSuggestionBatch` - cache sugestii AI (user_id, generated_at, expires_at, prompt, response)
- `IntegrationErrorLog` - logi błędów integracji

### 3. Serializery
```
myVOD/backend/myVOD/myVOD/serializers.py
```
- `AISuggestionsSerializer` - główna odpowiedź API
- `SuggestionItemSerializer` - pojedyncza sugestia
- `MovieAvailabilitySerializer` - dostępność na platformach

### 4. Testy (do weryfikacji po zmianach)
```
myVOD/backend/myVOD/services/tests/test_ai_suggestions_service.py
myVOD/backend/myVOD/myVOD/tests/test_ai_suggestions.py
```

### 5. Dokumentacja
```
AI_prompts/11.9 Plan implementacji endpointa GET suggestions.md
```
Zawiera kompletną specyfikację API i wymagania biznesowe.

## 🔧 Co konkretnie trzeba zrobić

### Krok 1: Przygotowanie środowiska
1. Zainstaluj Google Generative AI SDK:
   ```bash
   pip install google-generativeai
   ```
   
2. Dodaj do `.env` (lub `settings.py`):
   ```
   GEMINI_API_KEY=your_api_key_here
   ```

3. Skonfiguruj dostęp do API key w Django settings:
   ```python
   # myVOD/backend/myVOD/myVOD/settings.py
   GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
   ```

### Krok 2: Implementacja prawdziwej funkcji `_generate_mock_suggestions`

**Lokalizacja:** `myVOD/backend/myVOD/services/ai_suggestions_service.py`

**Obecna implementacja (do zastąpienia):**
```python
def _generate_mock_suggestions(user, user_movies):
    """
    MOCK function - generate movie suggestions.
    This should be replaced with actual AI integration (Gemini API).
    """
    # ... mock code ...
    return [
        {"tconst": "tt0111161", "justification": "..."},
        {"tconst": "tt0137523", "justification": "..."},
        # ...
    ]
```

**Nowa implementacja powinna:**

1. **Przygotować kontekst dla AI:**
   - Lista filmów z watchlisty użytkownika (tytuły, gatunki, oceny, lata)
   - Lista obejrzanych filmów użytkownika
   - Preferencje gatunkowe (na podstawie historii)

2. **Zbudować prompt dla Gemini:**
   ```
   You are a movie recommendation expert. Based on the user's watched movies and watchlist, 
   suggest 5 movies they might enjoy.
   
   User's Watchlist:
   - [Movie titles, genres, years, ratings]
   
   User's Watched Movies:
   - [Movie titles, genres, years, ratings]
   
   Requirements:
   - Suggest movies from the IMDB database
   - Provide justification for each recommendation (max 200 characters)
   - Return ONLY valid IMDB tconst IDs (format: ttXXXXXXX)
   - Focus on movies similar in genre/theme but not too obvious
   
   Return format (JSON):
   [
     {
       "tconst": "tt0468569",
       "justification": "Epic crime drama with outstanding performances..."
     },
     ...
   ]
   ```

3. **Wywołać Gemini API:**
   ```python
   import google.generativeai as genai
   from django.conf import settings
   
   genai.configure(api_key=settings.GEMINI_API_KEY)
   model = genai.GenerativeModel('gemini-pro')
   response = model.generate_content(prompt)
   ```

4. **Parsować odpowiedź:**
   - Wyciągnąć JSON z odpowiedzi
   - Walidować strukture
   - Sprawdzić czy `tconst` istnieje w bazie `Movie`
   - Odfiltrować nieprawidłowe sugestie

5. **Obsłużyć błędy:**
   - Timeout
   - Invalid API key
   - Rate limiting z Gemini
   - Nieprawidłowa odpowiedź (brak JSON, złe tconst)
   - Logować wszystkie błędy do `IntegrationErrorLog`

6. **Zwrócić listę sugestii:**
   ```python
   return [
       {"tconst": "tt0468569", "justification": "..."},
       {"tconst": "tt0816692", "justification": "..."},
       # ... max 5 filmów
   ]
   ```

### Krok 3: Wymagania implementacyjne

**Format odpowiedzi funkcji** (nie zmieniać!):
```python
[
    {
        "tconst": str,  # format: ttXXXXXXX
        "justification": str  # max 200 znaków
    },
    # ... max 5 elementów
]
```

**Wymagania biznesowe:**
- Maksymalnie 5 sugestii
- Każda sugestia musi mieć `tconst` istniejący w bazie `Movie`
- Uzasadnienie max 200 znaków
- Sugestie nie powinny zawierać filmów już na watchliście użytkownika
- Sugestie nie powinny zawierać filmów już obejrzanych (chyba że są usunięte z watchlisty)

**Error handling:**
- Wszystkie błędy z Gemini API powinny być catchowane
- Błędy logować przez `_log_integration_error(api_type="gemini", ...)`
- W przypadku błędu API, zwrócić pustą listę `[]` (nie crash'ować)
- Timeout dla Gemini API: max 30 sekund

**Logging:**
```python
# W przypadku błędu:
_log_integration_error(
    api_type="gemini",
    error_message=str(e),
    error_details={
        "prompt_length": len(prompt),
        "user_movies_count": len(user_movies),
        "error_type": type(e).__name__
    },
    user_id=user.id
)
```

### Krok 4: Testowanie

Po implementacji uruchom testy:
```bash
cd myVOD/backend/myVOD
python manage.py test services.tests.test_ai_suggestions_service myVOD.tests.test_ai_suggestions --verbosity 2
```

**Wszystkie 27 testów muszą przejść!**

Testy używają mocków dla wywołania AI, więc:
- Upewnij się, że nowa funkcja jest odpowiednio zmockowana w testach
- Możliwe że trzeba będzie zaktualizować mocki w testach, jeśli sygnatura funkcji się zmieni

### Krok 5: Testowanie manualne

1. Utwórz użytkownika testowego
2. Dodaj kilka filmów do watchlisty
3. Oznacz kilka jako obejrzane
4. Wywołaj endpoint:
   ```bash
   curl -X GET http://localhost:8000/api/suggestions/ \
     -H "Authorization: Bearer YOUR_JWT_TOKEN"
   ```

5. Sprawdź odpowiedź - powinna zawierać prawdziwe sugestie z Gemini

## 📊 Struktura danych

### Input (user_movies QuerySet):
```python
[
    {
        "id": 1,
        "user_id": UUID("..."),
        "tconst": "tt0816692",
        "tconst__primary_title": "Interstellar",
        "tconst__start_year": 2014,
        "tconst__avg_rating": 8.6,
        "tconst__genres": ["Sci-Fi", "Drama"],
        "watchlisted_at": datetime(...),
        "watched_at": None or datetime(...),
        "watchlist_deleted_at": None
    },
    # ...
]
```

### Expected Output (do zapisu w AiSuggestionBatch.response):
```json
[
    {
        "tconst": "tt0468569",
        "justification": "Epic crime drama with complex narrative and outstanding performances"
    },
    {
        "tconst": "tt1375666",
        "justification": "Mind-bending sci-fi thriller exploring dreams and reality"
    }
]
```

## ⚠️ Ważne uwagi

1. **Nie zmieniaj sygnatury funkcji** `_generate_mock_suggestions(user, user_movies)` - testy polegają na niej
2. **Nie zmieniaj struktury zwracanej listy** - serializer polega na tym formacie
3. **API key nie może być hardcoded** - używaj zmiennych środowiskowych
4. **Rate limiting Gemini** - pamiętaj o limitach API (może być potrzebny retry logic)
5. **Koszty API** - Gemini Pro jest darmowy do pewnego limitu, ale śledź usage
6. **Prompt engineering** - możesz iterować nad promptem, aby uzyskać lepsze rezultaty

## 📝 Checklist

- [ ] Zainstalowano `google-generativeai`
- [ ] Skonfigurowano `GEMINI_API_KEY` w settings
- [ ] Zaimplementowano funkcję wywołującą Gemini API
- [ ] Zbudowano odpowiedni prompt z kontekstem użytkownika
- [ ] Parsowanie i walidacja odpowiedzi Gemini
- [ ] Walidacja `tconst` względem bazy `Movie`
- [ ] Obsługa błędów i timeout
- [ ] Logowanie błędów do `IntegrationErrorLog`
- [ ] Wszystkie testy przechodzą (27/27)
- [ ] Testowanie manualne z prawdziwym użytkownikiem
- [ ] Dokumentacja kodu (docstring)

## 🔗 Przydatne linki

- Gemini API Documentation: https://ai.google.dev/docs
- Python SDK: https://github.com/google/generative-ai-python
- Prompt Engineering Guide: https://ai.google.dev/docs/prompt_best_practices

## 💡 Przykładowy kod (starter)

```python
import google.generativeai as genai
from django.conf import settings
import json
import logging

logger = logging.getLogger(__name__)

def _generate_mock_suggestions(user, user_movies):
    """
    Generate AI-powered movie suggestions using Google Gemini.
    
    Args:
        user: User instance
        user_movies: QuerySet of UserMovie with related Movie data
        
    Returns:
        List of dicts with 'tconst' and 'justification' keys
        
    Raises:
        No exceptions - catches all errors and returns empty list
    """
    try:
        # 1. Configure Gemini
        genai.configure(api_key=settings.GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-pro')
        
        # 2. Prepare user context
        watchlist = [m for m in user_movies if m.watchlisted_at and not m.watchlist_deleted_at]
        watched = [m for m in user_movies if m.watched_at]
        
        # 3. Build prompt
        prompt = _build_gemini_prompt(watchlist, watched)
        
        # 4. Call Gemini API
        response = model.generate_content(
            prompt,
            generation_config={
                'temperature': 0.7,
                'max_output_tokens': 1000,
            }
        )
        
        # 5. Parse and validate response
        suggestions = _parse_gemini_response(response.text)
        
        # 6. Validate tconst against database
        valid_suggestions = _validate_suggestions(suggestions)
        
        return valid_suggestions[:5]  # Max 5
        
    except Exception as e:
        logger.error(f"Gemini API error: {e}")
        _log_integration_error(
            api_type="gemini",
            error_message=str(e),
            error_details={"error_type": type(e).__name__},
            user_id=user.id
        )
        return []  # Return empty list on error

def _build_gemini_prompt(watchlist, watched):
    """Build prompt for Gemini with user context."""
    # TODO: Implement
    pass

def _parse_gemini_response(response_text):
    """Parse JSON from Gemini response."""
    # TODO: Implement JSON extraction and parsing
    pass

def _validate_suggestions(suggestions):
    """Validate tconst IDs against Movie database."""
    # TODO: Implement validation
    pass
```

---

**Powodzenia z implementacją! 🚀**

